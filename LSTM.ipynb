{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f17fd2-5b71-4519-90f1-058987ec6f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import math\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "# Function to limit memory usage\n",
    "def limit_memory(max_memory_gb):\n",
    "    process = psutil.Process(os.getpid())\n",
    "    max_memory_bytes = max_memory_gb * 1024 * 1024 * 1024\n",
    "    process.rlimit(psutil.RLIMIT_AS, (max_memory_bytes, max_memory_bytes))\n",
    "\n",
    "# Load historical and ground truth data\n",
    "def load_data(historical_file, ground_truth_file):\n",
    "    with open(historical_file, 'r') as file:\n",
    "        historical_data = [list(map(int, line.split())) for line in file]\n",
    "    \n",
    "    with open(ground_truth_file, 'r') as file:\n",
    "        ground_truth_data = [list(map(int, line.split())) for line in file]\n",
    "    \n",
    "    return np.array(historical_data), np.array(ground_truth_data)\n",
    "\n",
    "# Normalize the data\n",
    "def normalize_data(data):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    return scaled_data, scaler\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "def split_data(data, split_ratio=0.95):\n",
    "    split_index = int(len(data) * split_ratio)\n",
    "    train_data = data[:split_index]\n",
    "    val_data = data[split_index:]\n",
    "    return train_data, val_data\n",
    "\n",
    "# Prepare the data for LSTM\n",
    "def prepare_data(data, time_steps=12):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X.append(data[i:i + time_steps])\n",
    "        y.append(data[i + time_steps])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Build the LSTM model with hyperparameters\n",
    "def build_model(hp, input_shape):\n",
    "    model = Sequential()\n",
    "    units = hp.Int('units', min_value=10, max_value=100, step=10)\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.05, max_value=0.5, step=0.05)\n",
    "    learning_rate = hp.Choice('learning_rate', values=[0.0001, 0.001, 0.01, 0.1])\n",
    "    \n",
    "    model.add(LSTM(units=units, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units=units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=12))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Calculate RMSE, MAE, and MAPE\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    return rmse, mae, mape\n",
    "\n",
    "# Main function to train and evaluate the model\n",
    "def train_and_evaluate_model(historical_file, ground_truth_file):\n",
    "    start_time = time.time()  # Start time measurement\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    historical_data, ground_truth_data = load_data(historical_file, ground_truth_file)\n",
    "    historical_data, scaler = normalize_data(historical_data)\n",
    "    ground_truth_data = scaler.transform(ground_truth_data)\n",
    "    \n",
    "    # Split data into training and validation sets\n",
    "    train_historical, val_historical = split_data(historical_data)\n",
    "    train_ground_truth, val_ground_truth = split_data(ground_truth_data)\n",
    "    \n",
    "    # Prepare data for LSTM\n",
    "    X_train, y_train = prepare_data(train_historical)\n",
    "    X_val, y_val = prepare_data(val_historical)\n",
    "    \n",
    "    # Define the input shape\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    \n",
    "    # Initialize the tuner\n",
    "    tuner = kt.RandomSearch(\n",
    "        lambda hp: build_model(hp, input_shape),\n",
    "        objective='val_loss',\n",
    "        max_trials=20,  # Increased number of trials\n",
    "        executions_per_trial=5,  # Increased number of executions per trial\n",
    "        directory='my_dir',\n",
    "        project_name='lstm_tuning'\n",
    "    )\n",
    "    \n",
    "    # Perform hyperparameter tuning\n",
    "    tuner.search(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))\n",
    "    \n",
    "    # Get the best model\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    \n",
    "    # Predict on validation data\n",
    "    y_pred = best_model.predict(X_val)\n",
    "    \n",
    "    # Inverse transform the predictions and true values\n",
    "    y_pred_inv = scaler.inverse_transform(y_pred)\n",
    "    y_val_inv = scaler.inverse_transform(y_val)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rmse, mae, mape = calculate_metrics(y_val_inv, y_pred_inv)\n",
    "    \n",
    "    print(f'Best Parameters: {tuner.get_best_hyperparameters(num_trials=1)[0].values}')\n",
    "    print(f'RMSE: {rmse}')\n",
    "    print(f'MAE: {mae}')\n",
    "    print(f'MAPE: {mape}')\n",
    "    \n",
    "    end_time = time.time()  # End time measurement\n",
    "    print(f'Total Running Time: {end_time - start_time} seconds')\n",
    "\n",
    "# Usage\n",
    "train_and_evaluate_model('Train_Historical_Data.json', 'Train_Ground_Truth.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
